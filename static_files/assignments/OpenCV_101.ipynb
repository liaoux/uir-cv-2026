{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yEiwQEDcTKj"
      },
      "source": [
        "# Lab 1 Part 2: Introduction to Computer Vision with OpenCV\n",
        "\n",
        "**Student Name:**\n",
        "\n",
        "**Student ID:**\n",
        "\n",
        "**Date:** February 2026\n",
        "\n",
        "UIR, ESIN\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Introduction to OpenCV\n",
        "2. Getting Started with OpenCV\n",
        "3. Linear Filters\n",
        "4. Non-Linear Filters {#nonlinear-filters}\n",
        "5. Comprehensive Comparison: All Filters\n",
        "6. Exercise: Filter Challenge"
      ],
      "metadata": {
        "id": "WzCGPoB3Uhy9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTMheDMecTKr"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Introduction to OpenCV <a id='intro'></a>\n",
        "\n",
        "**OpenCV** (Open Source Computer Vision Library) is one of the most widely used open-source libraries for computer vision and image processing tasks.\n",
        "\n",
        "### Key Features:\n",
        "- **Over 2,500 algorithms** for image processing, video analysis, object detection, and machine learning\n",
        "- **Real-time processing** capabilities optimized for performance\n",
        "- **Cross-platform** support (Windows, macOS, Linux, Android, iOS)\n",
        "- **Multi-language** support (Python, C++, Java, MATLAB)\n",
        "- **Hardware acceleration** with CUDA and OpenCL for GPU processing\n",
        "- **Extensive documentation** and large community support\n",
        "\n",
        "### Main Applications:\n",
        "- Image and video processing\n",
        "- Object detection and recognition\n",
        "- Face detection and recognition\n",
        "- Motion tracking and analysis\n",
        "- Augmented reality\n",
        "- Robotics and autonomous vehicles\n",
        "- Medical imaging\n",
        "\n",
        "Originally developed by Intel in 1999, OpenCV has become the de facto standard for traditional computer vision tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxsRb5SacTKz"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Getting Started with OpenCV <a id='getting-started'></a>\n",
        "\n",
        "### Installation\n",
        "\n",
        "Install OpenCV using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WASea3rcTK2"
      },
      "outputs": [],
      "source": [
        "# Install OpenCV (run this in your terminal or uncomment to run here)\n",
        "# !pip install opencv-python opencv-contrib-python numpy matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yeAvAcMcTK7"
      },
      "source": [
        "### Basic Setup and Image Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NksWDQppcTK9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "\n",
        "# Configure matplotlib for better image display\n",
        "plt.rcParams['figure.figsize'] = (14, 7)\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "print(f\"OpenCV Version: {cv2.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmFQ15cTcTK_"
      },
      "source": [
        "### Helper Function: Display Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5smM-JCscTLD"
      },
      "outputs": [],
      "source": [
        "def display_images(images: list, titles: list, cmap: str = 'gray', figsize: Tuple[int, int] = (15, 5)):\n",
        "    \"\"\"\n",
        "    Display multiple images in a row.\n",
        "\n",
        "    Args:\n",
        "        images: List of images to display\n",
        "        titles: List of titles for each image\n",
        "        cmap: Colormap (default: 'gray')\n",
        "        figsize: Figure size\n",
        "    \"\"\"\n",
        "    n = len(images)\n",
        "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
        "\n",
        "    if n == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        axes[i].imshow(img, cmap=cmap)\n",
        "        axes[i].set_title(title, fontsize=12)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90T2n4YzcTLI"
      },
      "source": [
        "### Create Sample Images for Demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBMVQeRqcTLK"
      },
      "outputs": [],
      "source": [
        "# Create a synthetic grayscale image with geometric shapes\n",
        "img_clean = np.zeros((400, 400), dtype=np.uint8)\n",
        "cv2.rectangle(img_clean, (50, 50), (150, 150), 255, -1)\n",
        "cv2.circle(img_clean, (300, 100), 50, 200, -1)\n",
        "cv2.rectangle(img_clean, (200, 250), (350, 350), 150, -1)\n",
        "\n",
        "# Add Gaussian noise\n",
        "gaussian_noise = np.random.normal(0, 25, img_clean.shape).astype(np.float32)\n",
        "img_noisy_gaussian = np.clip(img_clean.astype(np.float32) + gaussian_noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Add salt-and-pepper noise\n",
        "img_noisy_sp = img_clean.copy()\n",
        "prob = 0.05\n",
        "random_matrix = np.random.random(img_clean.shape)\n",
        "img_noisy_sp[random_matrix < prob/2] = 0\n",
        "img_noisy_sp[random_matrix > 1 - prob/2] = 255\n",
        "\n",
        "display_images(\n",
        "    [img_clean, img_noisy_gaussian, img_noisy_sp],\n",
        "    ['Clean Image', 'Gaussian Noise', 'Salt-and-Pepper Noise']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daKxtmeycTLO"
      },
      "source": [
        "## 3. Linear Filters\n",
        "\n",
        "### What are Linear Filters?\n",
        "\n",
        "Linear filters apply **convolution** operations where each output pixel is a **weighted sum** of input pixels in a neighborhood.\n",
        "\n",
        "**General discrete form (2D convolution):**\n",
        "$$\n",
        "g[i,j] = \\sum_{m=1}^{M} \\sum_{n=1}^{N} f[m,n] \\cdot h[i-m, j-n]\n",
        "$$\n",
        "**\"Mask\", \"Kernel\", or \"Filter\"** refers to the small matrix $h$.\n",
        "\n",
        "where:\n",
        "- $f[m,n]$: input image pixels (size $M \\times N$)\n",
        "- $h$: kernel (e.g., $3 \\times 3$ or $5 \\times 5$)\n",
        "- $g[i,j]$: output image\n",
        "\n",
        "### Properties\n",
        "- **Linearity:** $f(a \\cdot x_1 + b \\cdot x_2) = a \\cdot f(x_1) + b \\cdot f(x_2)$\n",
        "- **Shift invariance:** Same kernel applied everywhere\n",
        "- **Superposition:** Sum of filtered inputs\n",
        "\n",
        "### Applications\n",
        "- Smoothing (Gaussian/mean filters)\n",
        "- Edge detection (Sobel, Prewitt)\n",
        "- Sharpening (Laplacian)\n",
        "- Blurring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKi1XR5kcTLQ"
      },
      "source": [
        "### 3.1 Box Filter (Average Filter)\n",
        "\n",
        "The simplest linear filter that replaces each pixel with the **average** of its neighbors.\n",
        "\n",
        "**Kernel (3×3):**\n",
        "$$\n",
        "K = \\frac{1}{9} \\begin{bmatrix}\n",
        "1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 \\\\\n",
        "1 & 1 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Use case:** Simple noise reduction, but causes blurring\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLr8jQr5cTLR"
      },
      "outputs": [],
      "source": [
        "# Apply box filter with different kernel sizes\n",
        "box_3x3 = cv2.boxFilter(img_noisy_gaussian, -1, (3, 3))\n",
        "box_7x7 = cv2.boxFilter(img_noisy_gaussian, -1, (7, 7))\n",
        "box_15x15 = cv2.boxFilter(img_noisy_gaussian, -1, (15, 15))\n",
        "\n",
        "display_images(\n",
        "    [img_noisy_gaussian, box_3x3, box_7x7, box_15x15],\n",
        "    ['Noisy Image', 'Box 3×3', 'Box 7×7', 'Box 15×15']\n",
        ")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Note: Larger kernel size = more smoothing but more blurring\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjxSbL5FcTLT"
      },
      "source": [
        "### 3.2 Gaussian Filter\n",
        "\n",
        "A **weighted average** where weights follow a Gaussian (normal) distribution. Gives more weight to nearby pixels.\n",
        "\n",
        "**2D Gaussian function:**\n",
        "$$\n",
        "G(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}\n",
        "$$\n",
        "\n",
        "where $\\sigma$ is the standard deviation controlling the spread.\n",
        "\n",
        "**Example 5×5 Gaussian kernel (σ ≈ 1):**\n",
        "$$\n",
        "K = \\frac{1}{256} \\begin{bmatrix}\n",
        "1 & 4 & 6 & 4 & 1 \\\\\n",
        "4 & 16 & 24 & 16 & 4 \\\\\n",
        "6 & 24 & 36 & 24 & 6 \\\\\n",
        "4 & 16 & 24 & 16 & 4 \\\\\n",
        "1 & 4 & 6 & 4 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Advantages over box filter:**\n",
        "- Better noise reduction\n",
        "- Less blurring of edges\n",
        "- No ringing artifacts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZhnwZlXcTLU"
      },
      "outputs": [],
      "source": [
        "# Apply Gaussian filter with different parameters\n",
        "# Syntax: cv2.GaussianBlur(image, kernel_size, sigmaX)\n",
        "# kernel_size must be odd numbers\n",
        "\n",
        "gauss_small = cv2.GaussianBlur(img_noisy_gaussian, (5, 5), 1)\n",
        "gauss_medium = cv2.GaussianBlur(img_noisy_gaussian, (9, 9), 2)\n",
        "gauss_large = cv2.GaussianBlur(img_noisy_gaussian, (15, 15), 3)\n",
        "\n",
        "display_images(\n",
        "    [img_noisy_gaussian, gauss_small, gauss_medium, gauss_large],\n",
        "    ['Noisy Image', 'Gaussian 5×5, σ=1', 'Gaussian 9×9, σ=2', 'Gaussian 15×15, σ=3']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcf309cTcTLX"
      },
      "source": [
        "### 3.3 Comparison: Box vs Gaussian Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgMHoOpOcTLY"
      },
      "outputs": [],
      "source": [
        "# Compare box and Gaussian filters with same kernel size\n",
        "box_9x9 = cv2.boxFilter(img_noisy_gaussian, -1, (9, 9))\n",
        "gauss_9x9 = cv2.GaussianBlur(img_noisy_gaussian, (9, 9), 0)\n",
        "\n",
        "display_images(\n",
        "    [img_noisy_gaussian, box_9x9, gauss_9x9],\n",
        "    ['Original Noisy', 'Box Filter 9×9', 'Gaussian Filter 9×9']\n",
        ")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Observation: Gaussian filter preserves edges better than box filter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip40H_ZGcTLZ"
      },
      "source": [
        "### 3.4 Custom Linear Filters with filter2D\n",
        "\n",
        "You can create **custom kernels** for specific effects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I63-HjL1cTLZ"
      },
      "outputs": [],
      "source": [
        "# Custom kernel examples\n",
        "\n",
        "# 1. Identity kernel (no change)\n",
        "kernel_identity = np.array([[0, 0, 0],\n",
        "                            [0, 1, 0],\n",
        "                            [0, 0, 0]], dtype=np.float32)\n",
        "\n",
        "# 2. Sharpening kernel\n",
        "kernel_sharpen = np.array([[0, -1, 0],\n",
        "                           [-1, 5, -1],\n",
        "                           [0, -1, 0]], dtype=np.float32)\n",
        "\n",
        "# 3. Edge detection (Laplacian)\n",
        "kernel_edge = np.array([[0, 1, 0],\n",
        "                        [1, -4, 1],\n",
        "                        [0, 1, 0]], dtype=np.float32)\n",
        "\n",
        "# 4. Emboss\n",
        "kernel_emboss = np.array([[-2, -1, 0],\n",
        "                          [-1, 1, 1],\n",
        "                          [0, 1, 2]], dtype=np.float32)\n",
        "\n",
        "# Apply custom filters\n",
        "img_identity = cv2.filter2D(img_clean, -1, kernel_identity)\n",
        "img_sharpen = cv2.filter2D(img_clean, -1, kernel_sharpen)\n",
        "img_edge = cv2.filter2D(img_clean, -1, kernel_edge)\n",
        "img_emboss = cv2.filter2D(img_clean, -1, kernel_emboss)\n",
        "\n",
        "display_images(\n",
        "    [img_clean, img_sharpen, img_edge, img_emboss],\n",
        "    ['Original', 'Sharpening', 'Edge Detection', 'Emboss']\n",
        ")\n",
        "\n",
        "print(\"\\nKernels used:\")\n",
        "print(\"Sharpen:\\n\", kernel_sharpen)\n",
        "print(\"\\nEdge:\\n\", kernel_edge)\n",
        "print(\"\\nEmboss:\\n\", kernel_emboss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_J90jMgcTLa"
      },
      "source": [
        "## 4. Non-Linear Filters {#nonlinear-filters}\n",
        "\n",
        "### What are Non-Linear Filters?\n",
        "\n",
        "Non-linear filters do **not** follow the superposition principle. **Cannot be implemented using convolution.**\n",
        "\n",
        "**Key characteristic:**\n",
        "$$\n",
        "f(a \\cdot x_1 + b \\cdot x_2) \\neq a \\cdot f(x_1) + b \\cdot f(x_2)\n",
        "$$\n",
        "\n",
        "### Why Use Non-Linear Filters?\n",
        "- **Better edge preservation** while reducing noise\n",
        "- **Effective for specific noise types** (e.g., salt-and-pepper noise)\n",
        "- **Can preserve image structure** better than linear filters\n",
        "\n",
        "### Common Non-Linear Filters:\n",
        "1. **Median filter** (order-statistic)\n",
        "2. **Bilateral filter** (edge-preserving)  \n",
        "3. **Morphological operations** (min/max filters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33e20uD1cTLb"
      },
      "source": [
        "### 4.1 Median Filter\n",
        "\n",
        "Replaces each pixel with the **median** value of neighboring pixels.\n",
        "\n",
        "**Algorithm:**\n",
        "1. Extract neighborhood pixels\n",
        "2. Sort them\n",
        "3. Select the middle value\n",
        "\n",
        "**Example (3×3 window):**\n",
        "```\n",
        "Neighborhood: [10, 12, 255, 15, 13, 14, 11, 16, 12]\n",
        "Sorted: [10, 11, 12, 12, 13, 14, 15, 16, 255]\n",
        "Median = 13\n",
        "```\n",
        "\n",
        "**Advantages:**\n",
        "- **Excellent for salt-and-pepper noise** (impulse noise)\n",
        "- **Preserves edges** better than linear filters\n",
        "- Removes outliers effectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO8auBRMcTLc"
      },
      "outputs": [],
      "source": [
        "# Apply median filter to salt-and-pepper noise\n",
        "median_3 = cv2.medianBlur(img_noisy_sp, 3)\n",
        "median_5 = cv2.medianBlur(img_noisy_sp, 5)\n",
        "median_7 = cv2.medianBlur(img_noisy_sp, 7)\n",
        "\n",
        "# Compare with Gaussian filter on same image\n",
        "gaussian_sp = cv2.GaussianBlur(img_noisy_sp, (5, 5), 0)\n",
        "\n",
        "display_images(\n",
        "    [img_noisy_sp, gaussian_sp, median_3, median_5],\n",
        "    ['Salt-Pepper Noise', 'Gaussian 5×5', 'Median 3×3', 'Median 5×5']\n",
        ")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Observation: Median filter is MUCH better for salt-and-pepper noise!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti-sFP33cTLd"
      },
      "source": [
        "### 4.2 Bilateral Filter\n",
        "\n",
        "An **edge-preserving** smoothing filter that considers both:\n",
        "1. **Spatial distance** (like Gaussian)\n",
        "2. **Intensity difference** (range filter)\n",
        "\n",
        "**Formula:**\n",
        "$$\n",
        "BF[I]_p = \\frac{1}{W_p} \\sum_{q \\in S} G_{\\sigma_s}(\\|p - q\\|) \\cdot G_{\\sigma_r}(|I_p - I_q|) \\cdot I_q\n",
        "$$\n",
        "\n",
        "**Detailed Bilateral Filter Formula:**\n",
        "\n",
        "$$\n",
        "g[i,j] = \\frac{1}{W_p} \\sum_m \\sum_n f[m,n] \\, g_s(|i-m|,|j-n|) \\, g_b(|f[m,n] - f[i,j]|)\n",
        "$$\n",
        "\n",
        "**Where:**\n",
        "$$\n",
        "g_s(m,n) = \\frac{1}{2\\pi\\sigma_s^2} e^{-\\frac{m^2+n^2}{2\\sigma_s^2}}, \\quad\n",
        "g_b(k) = \\frac{1}{\\sqrt{2\\pi}\\sigma_b} e^{-\\frac{k^2}{2\\sigma_b^2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "W_p = \\sum_m \\sum_n g_s(|i-m|,|j-n|) \\, g_b(|f[m,n] - f[i,j]|)\n",
        "$$\n",
        "\n",
        "**Non-Linear Operation** (Cannot be implemented using convolution)\n",
        "\n",
        "\n",
        "where:\n",
        "- $G_{\\sigma_s}$: Spatial Gaussian (distance weight)\n",
        "- $G_{\\sigma_r}$: Range Gaussian (intensity difference weight)  \n",
        "- $W_p$: Normalization factor\n",
        "\n",
        "**OpenCV Parameters:**\n",
        "- `d`: Diameter of pixel neighborhood\n",
        "- `sigmaColor`: Filter sigma in color space\n",
        "- `sigmaSpace`: Filter sigma in coordinate space\n",
        "\n",
        "**Key property:** Pixels with **similar intensities** are averaged; pixels with **different intensities** (edges) are preserved.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ync7Dc8cTLe"
      },
      "outputs": [],
      "source": [
        "# Apply bilateral filter\n",
        "# Syntax: cv2.bilateralFilter(image, d, sigmaColor, sigmaSpace)\n",
        "\n",
        "bilateral_1 = cv2.bilateralFilter(img_noisy_gaussian, 9, 75, 75)\n",
        "bilateral_2 = cv2.bilateralFilter(img_noisy_gaussian, 9, 150, 150)\n",
        "\n",
        "# Compare with Gaussian filter\n",
        "gaussian_comp = cv2.GaussianBlur(img_noisy_gaussian, (9, 9), 0)\n",
        "\n",
        "display_images(\n",
        "    [img_noisy_gaussian, gaussian_comp, bilateral_1, bilateral_2],\n",
        "    ['Noisy Image', 'Gaussian 9×9', 'Bilateral (σ=75)', 'Bilateral (σ=150)']\n",
        ")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Observation: Bilateral filter smooths flat regions while preserving edges!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR7mXtcscTLf"
      },
      "source": [
        "### 4.3 Morphological Filters: Erosion and Dilation\n",
        "\n",
        "**Min/Max filters** that operate on local neighborhoods.\n",
        "\n",
        "**Erosion (Min filter):**\n",
        "- Replaces pixel with **minimum** value in neighborhood\n",
        "- Shrinks bright regions\n",
        "- Removes small bright spots\n",
        "\n",
        "**Dilation (Max filter):**\n",
        "- Replaces pixel with **maximum** value in neighborhood\n",
        "- Expands bright regions\n",
        "- Fills small dark holes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBhGK2TXcTLg"
      },
      "outputs": [],
      "source": [
        "# Create structuring element (kernel)\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "# Apply morphological operations\n",
        "erosion = cv2.erode(img_clean, kernel, iterations=1)\n",
        "dilation = cv2.dilate(img_clean, kernel, iterations=1)\n",
        "\n",
        "# Opening: erosion followed by dilation (removes small bright spots)\n",
        "opening = cv2.morphologyEx(img_noisy_sp, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "# Closing: dilation followed by erosion (fills small dark holes)\n",
        "closing = cv2.morphologyEx(img_noisy_sp, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "display_images(\n",
        "    [img_clean, erosion, dilation],\n",
        "    ['Original', 'Erosion (Min)', 'Dilation (Max)']\n",
        ")\n",
        "\n",
        "display_images(\n",
        "    [img_noisy_sp, opening, closing],\n",
        "    ['Salt-Pepper Noise', 'Opening', 'Closing']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTNgki4WcTLi"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Comprehensive Comparison: All Filters <a id='comparison-all'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IALtnw2ecTLj"
      },
      "outputs": [],
      "source": [
        "# Apply all filters to Gaussian noise\n",
        "results_gaussian = [\n",
        "    (img_noisy_gaussian, 'Noisy (Gaussian)'),\n",
        "    (cv2.boxFilter(img_noisy_gaussian, -1, (7, 7)), 'Box Filter'),\n",
        "    (cv2.GaussianBlur(img_noisy_gaussian, (7, 7), 0), 'Gaussian Filter'),\n",
        "    (cv2.medianBlur(img_noisy_gaussian, 7), 'Median Filter'),\n",
        "    (cv2.bilateralFilter(img_noisy_gaussian, 9, 75, 75), 'Bilateral Filter')\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(18, 4))\n",
        "for i, (img, title) in enumerate(results_gaussian):\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "    axes[i].set_title(title, fontsize=11)\n",
        "    axes[i].axis('off')\n",
        "plt.suptitle('Comparison on Gaussian Noise', fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Apply all filters to salt-and-pepper noise\n",
        "results_sp = [\n",
        "    (img_noisy_sp, 'Noisy (Salt-Pepper)'),\n",
        "    (cv2.boxFilter(img_noisy_sp, -1, (7, 7)), 'Box Filter'),\n",
        "    (cv2.GaussianBlur(img_noisy_sp, (7, 7), 0), 'Gaussian Filter'),\n",
        "    (cv2.medianBlur(img_noisy_sp, 7), 'Median Filter'),\n",
        "    (cv2.bilateralFilter(img_noisy_sp, 9, 75, 75), 'Bilateral Filter')\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 5, figsize=(18, 4))\n",
        "for i, (img, title) in enumerate(results_sp):\n",
        "    axes[i].imshow(img, cmap='gray')\n",
        "    axes[i].set_title(title, fontsize=11)\n",
        "    axes[i].axis('off')\n",
        "plt.suptitle('Comparison on Salt-and-Pepper Noise', fontsize=14, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIuzvEDHcTLk"
      },
      "source": [
        "### Summary Table: When to Use Each Filter\n",
        "\n",
        "| Filter | Type | Best For | Pros | Cons |\n",
        "|--------|------|----------|------|------|\n",
        "| **Box Filter** | Linear | Quick smoothing | Fast, simple | Blurs edges significantly |\n",
        "| **Gaussian Filter** | Linear | General noise reduction | Smooth results, no artifacts | Blurs edges |\n",
        "| **Median Filter** | Non-linear | Salt-and-pepper noise | Preserves edges, removes outliers | Slower, can lose details |\n",
        "| **Bilateral Filter** | Non-linear | Edge-preserving smoothing | Excellent edge preservation | Computationally expensive |\n",
        "| **Morphological** | Non-linear | Shape processing, binary images | Structural operations | Limited to specific tasks |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dALtIdQHcTLl"
      },
      "source": [
        "# 6. Exercise: Filter Challenge\n",
        "\n",
        "**Challenge:** Find the **best filter combo** for Your images!\n",
        "\n",
        "1. **Upload ANY image** (pet, landscape, object, face, art...)\n",
        "2. Test **5 filter strategies**\n",
        "3. Use **PSNR + visual quality** to rank them\n",
        "4. **Explain** why the winner preserves faces best\n",
        "\n",
        "\n",
        "### PSNR: Peak Signal to Noise Ratio\n",
        "\n",
        "$$\\text{PSNR} = 20 \\log_{10} \\left( \\frac{255}{\\sqrt{\\text{MSE}}} \\right)$$\n",
        "\n",
        "**Higher = Better!**\n",
        "| Range | Quality |\n",
        "|-------|---------|\n",
        "| >40dB | Excellent |\n",
        "| 30-40 | Good |\n",
        "| <25   | Poor |"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, numpy as np, matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "%matplotlib inline\n",
        "\n",
        "def psnr(ref, test):\n",
        "    mse = np.mean((ref - test)**2)\n",
        "    return 20*np.log10(255/np.sqrt(mse)) if mse else float('inf')\n",
        "\n",
        "def add_sp_noise(img, salt_prob=0.08):\n",
        "    noisy = img.copy()\n",
        "    # Salt\n",
        "    noisy[np.random.random(img.shape) < salt_prob] = 255\n",
        "    # Pepper\n",
        "    noisy[np.random.random(img.shape) < salt_prob/2] = 0\n",
        "    return noisy\n",
        "\n",
        "print(\"Upload a portrait/selfie:\")\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded)[0]\n",
        "face = cv2.imread(filename, 0)\n",
        "face = cv2.resize(face, (400, 500))  # Portrait aspect\n",
        "\n",
        "# Add realistic noise\n",
        "noisy_face = add_sp_noise(face)\n",
        "\n",
        "# 5 COMPETING STRATEGIES (your lecture filters!)\n",
        "strategies = {\n",
        "    '1. Box 7x7': cv2.blur(noisy_face, (7,7)),\n",
        "    '2. Gaussian': cv2.GaussianBlur(noisy_face, (7,7), 2),\n",
        "    '3. Median 7': cv2.medianBlur(noisy_face, 7),\n",
        "    '4. Bilateral': cv2.bilateralFilter(noisy_face, 9, 50, 50),\n",
        "    '5. Gaussian→Median': cv2.medianBlur(cv2.GaussianBlur(noisy_face, (5,5), 1), 5)\n",
        "}\n",
        "\n",
        "# BATTLE VISUALIZATION\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "results = {}\n",
        "for i, (name, filtered) in enumerate(strategies.items()):\n",
        "    psnr_val = psnr(face, filtered)\n",
        "    results[name] = psnr_val\n",
        "    axes[i].imshow(filtered, cmap='gray')\n",
        "    axes[i].set_title(f'{name}\\nPSNR: {psnr_val:.1f}dB', fontsize=11)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "axes[5].imshow(face, cmap='gray')\n",
        "axes[5].set_title('Original (Clean)', fontsize=11)\n",
        "axes[5].axis('off')\n",
        "\n",
        "plt.suptitle('Filter Face-Off: Which One Wins?', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# RANKING TABLE\n",
        "print(\"\\n RANKING:\")\n",
        "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
        "print(\"Strategy\\t\\tPSNR\")\n",
        "print(\"-\"*30)\n",
        "for name, score in sorted_results:\n",
        "    print(f\"{name:<16} {score:>6.1f}\")\n"
      ],
      "metadata": {
        "id": "0gG1vOfE86Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report Your Findings:\n",
        "1. **Winner?** Which strategy recovered your image best?\n",
        "2. **Why?** Explain using filter properties (median=salt-pepper, bilateral=edges, etc.)\n",
        "3. **Parameter Play:** Try `cv2.bilateralFilter(..., 75, 75)` vs `(25, 25)`\n",
        "4. Why did YOUR #1 filter win? Connect to theory! (e.g., Median kills salt/pepper, Bilateral saves edges, Gaussian smooths...)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**SUBMIT:** `File → Print → Save as PDF` to Connect following this format `YourName_ID_FiltersLab.pdf`\n"
      ],
      "metadata": {
        "id": "-nuptD8L_ee0"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "opencv-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}